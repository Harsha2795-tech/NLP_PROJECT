{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install -q transformers datasets torch accelerate pandas gradio scikit-learn\n",
        "\n",
        "import os\n",
        "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
        "os.environ[\"WANDB_MODE\"] = \"disabled\"\n",
        "\n",
        "print(\"Libraries installed and W&B disabled.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bl8wo3cvQ9sB",
        "outputId": "92759e41-276f-4bb4-c46f-0fcfbbfd2bc7"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Libraries installed and W&B disabled.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, BertForSequenceClassification, TrainingArguments, Trainer\n",
        "from datasets import Dataset\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "import gradio as gr\n"
      ],
      "metadata": {
        "id": "oTBZhO3mSBIa"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "\n",
        "def tokenize_fn(batch):\n",
        "    return tokenizer(batch[\"review\"], truncation=True, padding=\"max_length\", max_length=256)\n"
      ],
      "metadata": {
        "id": "xu1-LPGkSHeK"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def batch_analyze(df_input, model):\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "    reviews = df_input[\"review\"].astype(str).tolist()\n",
        "\n",
        "    preds, probs = [], []\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for i in tqdm(range(0, len(reviews), 32)):\n",
        "            batch = reviews[i:i+32]\n",
        "            enc = tokenizer(batch, return_tensors=\"pt\", padding=True, truncation=True).to(device)\n",
        "\n",
        "            out = model(**enc)\n",
        "            logits = out.logits.cpu().numpy()\n",
        "\n",
        "            softmax = np.exp(logits) / np.exp(logits).sum(axis=1, keepdims=True)\n",
        "\n",
        "            preds.extend(logits.argmax(axis=1))\n",
        "            probs.extend(softmax.tolist())\n",
        "\n",
        "    inv_map = {1: \"positive\", 0: \"negative\", 2: \"neutral\"}\n",
        "\n",
        "    df_input[\"predicted\"] = [inv_map[int(p)] for p in preds]\n",
        "    df_input[\"confidence\"] = [probs[i][int(preds[i])] for i in range(len(preds))]\n",
        "\n",
        "    stats = df_input[\"predicted\"].value_counts(normalize=True).mul(100).round(2).to_dict()\n",
        "\n",
        "    return df_input, stats\n"
      ],
      "metadata": {
        "id": "IcigsGQySKiO"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def web_app(training_file, input_file):\n",
        "    # STEP A: Load training dataset\n",
        "    df_train = pd.read_csv(training_file.name)\n",
        "\n",
        "    # convert sentiment labels\n",
        "    label_map = {\"positive\": 1, \"negative\": 0, \"neutral\": 2}\n",
        "    df_train[\"labels\"] = df_train[\"sentiment\"].map(label_map)\n",
        "\n",
        "    # Convert to HF Dataset\n",
        "    dataset = Dataset.from_pandas(df_train)\n",
        "\n",
        "    # Tokenize training data\n",
        "    tokenized = dataset.map(tokenize_fn, batched=True)\n",
        "    tokenized.set_format(\"torch\", columns=[\"input_ids\",\"attention_mask\",\"labels\"])\n",
        "\n",
        "    # STEP B: Train the model\n",
        "    model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=3)\n",
        "\n",
        "    training_args = TrainingArguments(\n",
        "        output_dir=\"./ui_sentiment_model\",\n",
        "        per_device_train_batch_size=8,\n",
        "        num_train_epochs=5,\n",
        "        save_strategy=\"no\",\n",
        "        eval_strategy=\"no\",\n",
        "        report_to=None\n",
        "    )\n",
        "\n",
        "    trainer = Trainer(model=model, args=training_args, train_dataset=tokenized)\n",
        "    trainer.train()\n",
        "\n",
        "    # STEP C: Load input dataset\n",
        "    df_input = pd.read_csv(input_file.name)\n",
        "\n",
        "    # STEP D: Analyze input dataset\n",
        "    df_out, stats = batch_analyze(df_input, model)\n",
        "\n",
        "    # Convert stats dict â†’ text\n",
        "    stats_text = \"\\n\".join([f\"{k}: {v}%\" for k, v in stats.items()])\n",
        "\n",
        "    # Save output CSV\n",
        "    out_path = \"/tmp/predictions.csv\"\n",
        "    df_out.to_csv(out_path, index=False)\n",
        "\n",
        "    return stats_text, out_path\n"
      ],
      "metadata": {
        "id": "g7lK-OslSNfC"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ui = gr.Interface(\n",
        "    fn=web_app,\n",
        "    inputs=[\n",
        "        gr.File(label=\"ðŸ“¥ Upload TRAINING dataset (CSV with review + sentiment)\"),\n",
        "        gr.File(label=\"ðŸ“¥ Upload INPUT dataset (CSV with review only)\")\n",
        "    ],\n",
        "    outputs=[\n",
        "        gr.Textbox(label=\"ðŸ“Š Sentiment Statistics\"),\n",
        "        gr.File(label=\"ðŸ“„ Download Predictions CSV\")\n",
        "    ],\n",
        "    title=\"Sentiment Analysis â€” FULL Training + Batch Prediction\",\n",
        "    description=\"Upload training & input CSV. The model will train and analyze automatically.\"\n",
        ")\n",
        "\n",
        "ui.launch(share=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 611
        },
        "id": "mFTX_UGXSPvW",
        "outputId": "99e7716d-4cf0-4aab-8b2f-35b987a89ce2"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://2b3f8dfc744074b00f.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://2b3f8dfc744074b00f.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    }
  ]
}